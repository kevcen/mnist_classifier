{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    image, label = train_dataset[52]\n",
    "    plt.imshow(image.squeeze())\n",
    "    plt.title(f'THIS IS {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128) #28x28 to 128 (pixels to 128 features)\n",
    "        self.fc2 = nn.Linear(128, 10) # 128 features to 10 (0 - 9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) #flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = SimpleNN() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3588151124589987\n",
      "Epoch 2/5, Loss: 0.1686050516328832\n",
      "Epoch 3/5, Loss: 0.11658498387374698\n",
      "Epoch 4/5, Loss: 0.08745877094902416\n",
      "Epoch 5/5, Loss: 0.06909481643327772\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "def train_model(num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            # find maxima/minima\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.21%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing the model\n",
    "def test_model():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total}%')\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
